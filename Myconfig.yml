language: "zh"

policies:
  - name: "rasa.core.policies.ted_policy.TEDPolicy"
    epochs: 200
    featurizer:
      - name: MaxHistoryTrackerFeaturizer
        max_history: 4
        state_featurizer:
          - name: LabelTokenizerSingleStateFeaturizer
  - name: "rasa.core.policies.memoization.MemoizationPolicy"
    max_history: 4
  - name: "rasa.core.policies.mapping_policy.MappingPolicy"
  - name: "rasa.core.policies.fallback.FallbackPolicy"
    nlu_threshold: 0.6
    core_threshold: 0.3
    fallback_action_name: 'action_donknow'

pipeline:
  - name: "MitieNLP"
    model: "data/total_word_feature_extractor_zh.dat"
  - name: "JiebaTokenizer"
    dictionary_path: "jieba_userdict"
  - name: "MitieEntityExtractor"
  - name: "EntitySynonymMapper"
  - name: "RegexFeaturizer"
  - name: "MitieFeaturizer"
  - name: "SklearnIntentClassifier"

#pipeline:
#  - name: HFTransformersNLP
#    # Name of the language model to use
#    model_name: "bert"
#
#    # Pre-Trained weights to be loaded
#    model_weights: "bert-base-chinese"
#
#    # An optional path to a specific directory to download and
#    # cache the pre-trained model weights.
#    # The `default` cache_dir can be "C:/Users/username/.cache/torch/transformers"
#    # OR ~/.cache/torch/transformers
#    # See https://huggingface.co/transformers/installation.html#caching-models
#    cache_dir: null
#
#  - name: "LanguageModelTokenizer"
#    # Flag to check whether to split intents
#    intent_tokenization_flag: False
#    # Symbol on which intent should be split
#    intent_split_symbol: "_"
#    # LanguageModelFeaturizer type: Dense featurizer
#  - name: "LanguageModelFeaturizer"
#  - name: "MitieNLP"
#    model: "data/total_word_feature_extractor_zh.dat"
#  - name: "MitieEntityExtractor"
#  - name: "EntitySynonymMapper"
#  - name: "RegexFeaturizer"
#    # SklearnIntentClassifier requires dense_features for user messages
#  - name: "SklearnIntentClassifier"

